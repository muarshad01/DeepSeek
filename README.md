## DeepSeek
1. [Build DeepSeek from Scratch](https://www.youtube.com/playlist?list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)


| Lecture | Notes | Date Updated |
|---|---|---|
| [Lecture 01 - Build DeepSeek from Scratch: Series Introduction](https://www.youtube.com/watch?v=QWNxQIq0hMo&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=1)|  [Notes01](https://github.com/muarshad01/LLM/blob/main/Notes/lecture01_notes.md)| |
| [Lecture 02 - DeepSeek Basics](https://www.youtube.com/watch?v=WjhDDeZ7DvM&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=2)|  [Notes02](https://github.com/muarshad01/LLM/blob/main/Notes/lecture02_notes.md)| |
| [Lecture 03 - LLM Architecture in 1 hour - Journey of token through the LLM Architecture](https://www.youtube.com/watch?v=rkEYwH4UGa4&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes03](https://github.com/muarshad01/LLM/blob/main/Notes/lecture03_notes.md)| |
| [Lecture 04 - The Attention Mechanism 1 hour explanation](https://www.youtube.com/watch?v=K45ze9Yd5UE&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes04](https://github.com/muarshad01/LLM/blob/main/Notes/lecture04_notes.md)| |
| [Lecture 05 - Self Attention Mechanism - Handwritten from scratch](https://www.youtube.com/watch?v=s8mskq-nzec&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=5)|  [Notes05](https://github.com/muarshad01/LLM/blob/main/Notes/lecture05_notes.md)| |
| [Lecture 06 - Causal Attention Explained: Don't Peek into the Future!](https://www.youtube.com/watch?v=c6Kkj6iLeBg&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=6)|  [Notes06](https://github.com/muarshad01/LLM/blob/main/Notes/lecture06_notes.md)| |
| [Lecture 07 - Multi-Head Attention Visually Explained](https://www.youtube.com/watch?v=qbN4ulK-bZA&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=7)|  [Notes07](https://github.com/muarshad01/LLM/blob/main/Notes/lecture07_notes.md)| |
| [Lecture 08 - Multi-Head Attention Handwritten from Scratch](https://www.youtube.com/watch?v=rvsEW-EsD-Y&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=8)|  [Notes08](https://github.com/muarshad01/LLM/blob/main/Notes/lecture08_notes.md)| |
| [Lecture 09 - Key Value Cache from Scratch: The good side and the bad side](https://www.youtube.com/watch?v=IDwTiS4_bKo&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=9)|  [Notes09](https://github.com/muarshad01/LLM/blob/main/Notes/lecture09_notes.md)| |
| [Lecture 10 - Multi-Query Attention Explained - Dealing with KV Cache Memory Issues Part 1](https://www.youtube.com/watch?v=Z6B51Odtn-Y&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms&index=10)|  [Notes10](https://github.com/muarshad01/LLM/blob/main/Notes/lecture10_notes.md)| |
| [Lecture 11 - Understand Grouped Query Attention (GQA) - The final frontier before latent attention](https://www.youtube.com/watch?v=kx3rETIxo4Q&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes11](https://github.com/muarshad01/LLM/blob/main/Notes/lecture11_notes.md)| |
| [Lecture 12 - Multi-Head Latent Attention From Scratch - One of the major DeepSeek innovation](https://www.youtube.com/watch?v=NlDQUj1olXM&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes12](https://github.com/muarshad01/LLM/blob/main/Notes/lecture12_notes.md)| |
| [Lecture 13 - Multi-Head Latent Attention Coded from Scratch in Python](https://www.youtube.com/watch?v=mIaWmJVrMpc&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes13](https://github.com/muarshad01/LLM/blob/main/Notes/lecture13_notes.md)| |
| [Lecture 14 - Integer and Binary Positional Encodings - Journey towards Rotary Positional Encodings (RoPE)](https://www.youtube.com/watch?v=rP0CoTxe5gU&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes14](https://github.com/muarshad01/LLM/blob/main/Notes/lecture14_notes.md)| |
| [Lecture 15 - All about Sinusoidal Positional Encodings - Whatâ€™s with the weird sin-cos formula?](https://www.youtube.com/watch?v=bQCQ7VO-TWU&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes15](https://github.com/muarshad01/LLM/blob/main/Notes/lecture15_notes.md)| |
| [Lecture 16 - Rotary Positional Encodings - Explained Visually](https://www.youtube.com/watch?v=a17DlNxkv2k&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes16](https://github.com/muarshad01/LLM/blob/main/Notes/lecture16_notes.md)| |
| [Lecture 17 - How DeepSeek exactly implemented Latent Attention - MLA + RoPE](https://www.youtube.com/watch?v=m1x8vA_Tscc&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes17](https://github.com/muarshad01/LLM/blob/main/Notes/lecture17_notes.md)| |
| [Lecture 18 - Mixture of Experts (MoE) Introduction](https://www.youtube.com/watch?v=v7U21meXd6Y&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes18](https://github.com/muarshad01/LLM/blob/main/Notes/lecture18_notes.md)| |
| [Lecture 19 - Mixture of Experts Hands on Demonstration - Visual Explanation](https://www.youtube.com/watch?v=yw6fpYPJ7PI&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes19](https://github.com/muarshad01/LLM/blob/main/Notes/lecture19_notes.md)| |
| [Lecture 20 - Mixture of Experts Balancing Techniques - Auxiliary Loss - Load Balancing - Capacity Factor](https://www.youtube.com/watch?v=nRadcspta_8&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes20](https://github.com/muarshad01/LLM/blob/main/Notes/lecture20_notes.md)| |
| [Lecture 21 - How DeepSeek rewrote Mixture of Experts (MoE)?](https://www.youtube.com/watch?v=KnSIZ83iPKs&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes21](https://github.com/muarshad01/LLM/blob/main/Notes/lecture21_notes.md)| |
| [Lecture 22 - Code Mixture of Experts (MoE) from Scratch in Python
](https://www.youtube.com/watch?v=W7ktPe1HfZs&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes22](https://github.com/muarshad01/LLM/blob/main/Notes/lecture22_notes.md)| |
| [Lecture 23 - Multi-Token Prediction Introduction](https://www.youtube.com/watch?v=tMtHAAg0UT4&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes23](https://github.com/muarshad01/LLM/blob/main/Notes/lecture23_notes.md)| |
| [Lecture 24 - How DeepSeek rewrote Multi-Token Prediction (MTP)?](https://www.youtube.com/watch?v=4GmwJLvwaXE&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes24](https://github.com/muarshad01/LLM/blob/main/Notes/lecture24_notes.md)| |
| [Lecture 25 - Multi Token Prediction (MTP) Coded from Scratch](https://www.youtube.com/watch?v=lyHe8_JHoVI&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes25](https://github.com/muarshad01/LLM/blob/main/Notes/lecture25_notes.md)| |
| [Lecture 26 - Introduction to LLM Quantization](https://www.youtube.com/watch?v=0U9l3-r6jVE&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes26](https://github.com/muarshad01/LLM/blob/main/Notes/lecture26_notes.md)| |
| [Lecture 27 - How DeepSeek Rewrote Quantization Part 1 - Mixed Precision - Fine-grained quantization](https://www.youtube.com/watch?v=xftka2aXnm4&list=PLPTV0NXA_ZSiOpKKlHCyOq9lnp-dLvlms)|  [Notes27](https://github.com/muarshad01/LLM/blob/main/Notes/lecture27_notes.md)| |
| [Lecture 28]()|  [Notes28](https://github.com/muarshad01/LLM/blob/main/Notes/lecture28_notes.md)| |
| [Lecture 29]()|  [Notes29](https://github.com/muarshad01/LLM/blob/main/Notes/lecture29_notes.md)| |
| [Lecture 30]()|  [Notes30](https://github.com/muarshad01/LLM/blob/main/Notes/lecture30_notes.md)| |

***
