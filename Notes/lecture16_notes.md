* 40:00

* Why don't we add positional encodings to query and key vectors, which encoded relative token information.
* If we add posotional encdings at that later stage, we would not pollute the meaning carried by token embeddings.
* Rotary Positonal Encoding (RoPE) exploit this idea along with the rotation intuition, which we looked at earlier.

***
